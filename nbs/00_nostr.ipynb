{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp nostr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nostr\n",
    "\n",
    "> key adjustments to python-nostr to make sure things work properly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository relies heavily on [python-nostr](https://github.com/jeffthibault/python-nostr), which is still in active development. There are a few features that are not yet integrated into the python-nostr library that I will add here. The classes listed in here will be used in the rebroadcastr client instead of using the classes directly from python nostr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from nostr import key\n",
    "from nostr import bech32\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrivateKey class\n",
    "adding `from_hex` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class PrivateKey(key.PrivateKey):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_hex(cls, hex: str) -> 'PrivateKey':\n",
    "        return cls(bytes.fromhex(hex))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests\n",
    "make sure we can generate private keys in various ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_key = PrivateKey()\n",
    "\n",
    "assert private_key.hex() == PrivateKey.from_hex(private_key.hex()).hex()\n",
    "assert private_key.bech32() == PrivateKey.from_nsec(private_key.bech32()).bech32()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PublicKey class\n",
    "adding `from_hex` and `from_npub` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from nostr import bech32\n",
    "\n",
    "\n",
    "class PublicKey(key.PublicKey):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_npub(cls, npub: str):\n",
    "        \"\"\" Load a PublicKey from its bech32/nsec form \"\"\"\n",
    "        hrp, data, spec = bech32.bech32_decode(npub)\n",
    "        raw_bytes = bech32.convertbits(data, 5, 8)[:-1]\n",
    "        return cls(bytes(raw_bytes))\n",
    "\n",
    "    @classmethod\n",
    "    def from_hex(cls, hex: str) -> 'PrivateKey':\n",
    "        return cls(bytes.fromhex(hex))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests\n",
    "make sure we can generate public keys in various ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_key = PublicKey(private_key.raw_secret)\n",
    "\n",
    "assert public_key.hex() == PublicKey.from_hex(public_key.hex()).hex()\n",
    "assert public_key.bech32() == PublicKey.from_npub(public_key.bech32()).bech32()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relay class changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "from threading import Lock\n",
    "from typing import Union\n",
    "from queue import Queue\n",
    "from nostr import message_pool\n",
    "from nostr import relay, relay_manager\n",
    "from nostr.relay import RelayPolicy\n",
    "from nostr.message_pool import EventMessage, NoticeMessage, EndOfStoredEventsMessage\n",
    "from nostr.message_type import RelayMessageType\n",
    "from nostr.event import Event"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to make a critical change to the `MessagePool` class that allows us to keep multiple of an event if it came from a separate relay. We now tell the message_pool to store any unique event/url combination instead of just a unique id\n",
    "\n",
    "This is now set with a `first_reponse_only` arg that defaults to True - in the case of `rebroadcastr` we will primarily set to False so that we can check for a message on multiple relays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MessagePool(relay_manager.MessagePool):\n",
    "    def __init__(self, first_response_only: bool = True):\n",
    "        self.first_response_only = first_response_only\n",
    "        self.events: Queue[EventMessage] = Queue()\n",
    "        self.notices: Queue[NoticeMessage] = Queue()\n",
    "        self.eose_notices: Queue[EndOfStoredEventsMessage] = Queue()\n",
    "        self._unique_objects: set = set()\n",
    "        self.lock: Lock = Lock()\n",
    "\n",
    "    def __init__(self, first_response_only: bool = True) -> None:\n",
    "        self.first_response_only = first_response_only\n",
    "\n",
    "    def _process_message(self, message: str, url: str):\n",
    "        message_json = json.loads(message)\n",
    "        message_type = message_json[0]\n",
    "        if message_type == RelayMessageType.EVENT:\n",
    "            subscription_id = message_json[1]\n",
    "            e = message_json[2]\n",
    "            event = Event(e['pubkey'], e['content'], e['created_at'], e['kind'], e['tags'], e['id'], e['sig'])\n",
    "            with self.lock:\n",
    "                if self.first_response_only:\n",
    "                    object_id = event.id\n",
    "                else:\n",
    "                    object_id = f'{event.id}:{url}'\n",
    "                if object_id not in self._unique_objects:\n",
    "                    self.events.put(EventMessage(event, subscription_id, url))\n",
    "                    self._unique_objects.add(event.id)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a context manager for connections for both the `Relay` and `RelayManager` classes. The `Relay` class also gets a new method to make sure that we can open a single relay connection - the connect method has to be called with threading to allow the python script to continue even when we are only connecting to a single relay. An `is_connected` property also lets us easily check the connection status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Connection:\n",
    "    def __init__(self, relay_or_manager: Union[relay.Relay, relay_manager.RelayManager],\n",
    "                 *args, **kwargs):\n",
    "        self.relay_manager = relay_or_manager\n",
    "        self.conn = self.relay_manager.open_connections(*args, **kwargs)\n",
    "    def __enter__(self):\n",
    "        return self.conn\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.relay_manager.close_connections()\n",
    "\n",
    "\n",
    "class Relay(relay.Relay):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_json_object(), indent=2)\n",
    "\n",
    "    @property\n",
    "    def is_connected(self) -> bool:\n",
    "        return False if self.ws.sock is None else self.ws.sock.connected\n",
    "    \n",
    "    def open_connections(self, ssl_options: dict={}):\n",
    "        threading.Thread(\n",
    "                target=self.connect,\n",
    "                args=(ssl_options,),\n",
    "                name=f\"{self.url}-thread\"\n",
    "        ).start()\n",
    "    \n",
    "    def close_connections(self):\n",
    "        self.close()\n",
    "    \n",
    "    def connection(self, *args, **kwargs):\n",
    "        return Connection(self, *args, **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_relay = Relay(url='wss://relay.nostr.ch',\n",
    "                policy=RelayPolicy(),\n",
    "                message_pool=MessagePool()\n",
    "                )\n",
    "\n",
    "assert not a_relay.is_connected\n",
    "with a_relay.connection():\n",
    "    time.sleep(1)\n",
    "    assert a_relay.is_connected\n",
    "assert not a_relay.is_connected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RelayManager class changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from nostr import relay_manager\n",
    "from nostr.relay import RelayPolicy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RelayManager` class gets a connection status attribute, an `__iter__` method, and now references our updated `Relay` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class RelayManager(relay_manager.RelayManager):\n",
    "    def __init__(self, first_response_only: bool = True,  *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.relays: dict[str, Relay] = {}\n",
    "        self.message_pool = MessagePool(first_response_only=first_response_only)\n",
    "        self._is_connected = False\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.relays.values())\n",
    "    \n",
    "    def connection(self, *args, **kwargs):\n",
    "        return Connection(self, *args, **kwargs)\n",
    "    \n",
    "    def open_connections(self, ssl_options: dict=None):\n",
    "        for relay in self.relays.values():\n",
    "            threading.Thread(\n",
    "                target=relay.connect,\n",
    "                args=(ssl_options,),\n",
    "                name=f\"{relay.url}-thread\"\n",
    "            ).start()\n",
    "        time.sleep(1)\n",
    "        self.remove_closed_relays()\n",
    "        assert all(self.connection_statuses.values())\n",
    "        self._is_connected = True\n",
    "    \n",
    "    def close_connections(self):\n",
    "        for relay in self.relays.values():\n",
    "            if relay.is_connected:\n",
    "                relay.close()\n",
    "        assert not any(self.connection_statuses.values())\n",
    "        self._is_connected = False\n",
    "\n",
    "    def remove_closed_relays(self):\n",
    "        for url, connected in self.connection_statuses.items():\n",
    "            if not connected:\n",
    "                warnings.warn(\n",
    "                    f'{url} is not connected... removing relay.'\n",
    "                )\n",
    "                self.remove_relay(url=url)\n",
    "\n",
    "    def add_relay(self, url: str, read: bool=True, write: bool=True, subscriptions={}):\n",
    "        policy = RelayPolicy(read, write)\n",
    "        relay = Relay(url, policy, self.message_pool, subscriptions)\n",
    "        self.relays[url] = relay\n",
    "    \n",
    "    def remove_relay(self, url: str):\n",
    "        if self.relays[url].is_connected:\n",
    "            self.relays[url].close\n",
    "        self.relays.pop(url)\n",
    "\n",
    "    @property\n",
    "    def connection_statuses(self) -> dict:\n",
    "        \"\"\"gets the url and connection statuses of relays\n",
    "\n",
    "        Returns:\n",
    "            dict: bool of connection statuses\n",
    "        \"\"\"\n",
    "        statuses = [relay.is_connected for relay in self]\n",
    "        return dict(zip(self.relays.keys(), statuses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening\n",
      "{'wss://relay.nostr.ch': True, 'wss://relay.damus.io': True}\n",
      "closing\n",
      "{'wss://relay.nostr.ch': False, 'wss://relay.damus.io': False}\n"
     ]
    }
   ],
   "source": [
    "manager = RelayManager()\n",
    "urls=['wss://relay.nostr.ch', 'wss://relay.damus.io']\n",
    "for url in urls:\n",
    "    manager.add_relay(url=url)\n",
    "\n",
    "with manager.connection():\n",
    "    print('opening')\n",
    "    time.sleep(1)\n",
    "    print(manager.connection_statuses)\n",
    "    assert all(manager.connection_statuses.values())\n",
    "    print('closing')\n",
    "print(manager.connection_statuses)\n",
    "assert not any(manager.connection_statuses.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rebroadcastr-nbdev",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
